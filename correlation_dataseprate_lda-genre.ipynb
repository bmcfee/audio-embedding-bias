{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "from ast import literal_eval\n",
    "import re\n",
    "import pickle\n",
    "import collections\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('class-map-10.json', 'r') as f: # only consider 10 classes of Openmic dataset\n",
    "    class_map = json.load(f)\n",
    "    \n",
    "# use a dict to align the classes between Openmic dataset (key) and Irmas dataset (val)\n",
    "class_align = {'cello': 'cel',\n",
    "               'clarinet': 'cla',\n",
    "               'flute': 'flu',\n",
    "               'guitar': ['gac', 'gel'],\n",
    "               'organ': 'org',\n",
    "               'piano': 'pia',\n",
    "               'saxophone': 'sax',\n",
    "               'trumpet': 'tru',\n",
    "               'violin': 'vio',\n",
    "               'voice': 'voi'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# irmas genre information: country-folk ([cou_fol]), classical ([cla]), pop-rock ([pop-roc]), latin-soul ([lat-sou]).\n",
    "aligned_genre = ['pop_roc', 'jazz_blue', 'classical', 'country_folk', 'latin_soul']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irmas\n",
      "irmas/openl3\n",
      "irmas/openl3/features\n",
      "irmas/openl3/keys\n",
      "irmas/vggish\n",
      "irmas/vggish/features\n",
      "irmas/vggish/keys\n",
      "irmas/yamnet\n",
      "irmas/yamnet/features\n",
      "irmas/yamnet/keys\n",
      "openmic\n",
      "openmic/openl3\n",
      "openmic/openl3/features\n",
      "openmic/openl3/keys\n",
      "openmic/vggish\n",
      "openmic/vggish/features\n",
      "openmic/vggish/keys\n",
      "openmic/yamnet\n",
      "openmic/yamnet/features\n",
      "openmic/yamnet/keys\n"
     ]
    }
   ],
   "source": [
    "# load embeddings\n",
    "embeddings = h5py.File('embeddings.h5', 'r')\n",
    "\n",
    "def printname(name):\n",
    "    print(name)\n",
    "embeddings.visit(printname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenL3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = 'openl3'\n",
    "debias_method = '-lda-genre'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## irmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167625, 512) (167625,)\n",
      "(6705,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b227e20d1a4d8b8b01c1034428e121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6705, 512) (6705,)\n"
     ]
    }
   ],
   "source": [
    "feature = np.array(embeddings['irmas'][embedding]['features'])\n",
    "keys_ori = np.array(embeddings['irmas'][embedding]['keys'])\n",
    "print(feature.shape, keys_ori.shape)\n",
    "\n",
    "key_clip = np.unique(keys_ori)\n",
    "print(key_clip.shape)\n",
    "\n",
    "feature_clip = []\n",
    "\n",
    "for key in tqdm(key_clip):\n",
    "    feature_clip.append(np.mean(feature[keys_ori[:]==key,:],axis=0))\n",
    "    \n",
    "feature_clip = np.array(feature_clip)\n",
    "key_clip = np.array([str(k, 'utf-8') for k in key_clip])\n",
    "print(feature_clip.shape, key_clip.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_train = set(pd.read_csv('irmas_train.csv', header=None, squeeze=True))\n",
    "key_test = set(pd.read_csv('irmas_test.csv', header=None, squeeze=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These loops go through all sample keys, and save their row numbers to either idx_train or idx_test\n",
    "idx_train, idx_test = [], []\n",
    "\n",
    "for k in range(len(key_clip)):\n",
    "    if str(key_clip[k]) in key_train:\n",
    "        idx_train.append(k)\n",
    "    elif str(key_clip[k]) in key_test:\n",
    "        idx_test.append(k)\n",
    "    else:\n",
    "        # This should never happen, but better safe than sorry.\n",
    "        raise RuntimeError('Unknown sample key={}! Abort!'.format(key_clip[k]))\n",
    "        \n",
    "# cast the idx_* arrays to numpy structures\n",
    "idx_train = np.asarray(idx_train)\n",
    "idx_test = np.asarray(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_train = np.array(key_clip[idx_train])\n",
    "key_train_genre = [key[key.rindex('[')+1:key.rindex(']')] for key in key_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cla', 'cou_fol', 'jaz_blu', 'lat_sou', 'pop_roc'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(key_train_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align genre\n",
    "key_train_genre = ['jazz_blue' if item =='jaz_blu' else item for item in key_train_genre]\n",
    "key_train_genre = ['classical' if item =='cla' else item for item in key_train_genre]\n",
    "key_train_genre = ['country_folk' if item =='cou_fol' else item for item in key_train_genre]\n",
    "key_train_genre = ['latin_soul' if item =='lat_sou' else item for item in key_train_genre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'pop_roc': 1853,\n",
       "         'classical': 1240,\n",
       "         'jazz_blue': 1539,\n",
       "         'country_folk': 365,\n",
       "         'latin_soul': 42})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(key_train_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5039, 512) (5039,) (5039,)\n"
     ]
    }
   ],
   "source": [
    "X_train_ir = feature_clip[idx_train,:]\n",
    "Y_ir = np.zeros(len(X_train_ir))\n",
    "Y_genre_ir = np.array(key_train_genre)\n",
    "\n",
    "print(X_train_ir.shape, Y_ir.shape, Y_genre_ir.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openmic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900000, 512) (1900000,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9824a7df3245f7810f46d4c23ae32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 512) (20000,)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# openmic: openl3 embedding\n",
    "feature = np.array(embeddings['openmic'][embedding]['features'])\n",
    "keys = np.array(embeddings['openmic'][embedding]['keys'])\n",
    "print(feature.shape, keys.shape)\n",
    "\n",
    "key_clip = np.unique(keys)\n",
    "\n",
    "feature_clip = []\n",
    "\n",
    "for key in tqdm(key_clip):\n",
    "    feature_clip.append(np.mean(feature[keys[:]==key,:],axis=0))\n",
    "    \n",
    "feature_clip = np.array(feature_clip)\n",
    "print(feature_clip.shape, key_clip.shape)\n",
    "\n",
    "key_clip = np.array([str(k, 'utf-8') for k in key_clip])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train: 14915,  # Test: 5085\n"
     ]
    }
   ],
   "source": [
    "# train-test split\n",
    "data_root = 'openmic-2018/'\n",
    "train_set = set(pd.read_csv(data_root + 'openmic2018_train.csv', header=None, squeeze=True))\n",
    "test_set = set(pd.read_csv(data_root + 'openmic2018_test.csv', header=None, squeeze=True))\n",
    "print('# Train: {},  # Test: {}'.format(len(train_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train, idx_test = [], []\n",
    "\n",
    "for idx, n in enumerate(key_clip):\n",
    "    if n in train_set:\n",
    "        idx_train.append(idx)\n",
    "    elif n in test_set:\n",
    "        idx_test.append(idx)\n",
    "    else:\n",
    "        raise RuntimeError('Unknown sample key={}! Abort!'.format(key_clip[n]))\n",
    "        \n",
    "idx_train = np.asarray(idx_train)\n",
    "idx_test = np.asarray(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14915"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key-label map using the information from the dataset source\n",
    "meta = pd.read_csv(data_root + 'openmic-2018-metadata.csv')\n",
    "train_genre_meta = list(meta['track_genres'][idx_train])\n",
    "len(train_genre_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088b7fc2658f437185dab0e11ae3e3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "key_genre_om = []\n",
    "\n",
    "for k in tqdm(range(len(train_genre_meta))):\n",
    "    if isinstance(train_genre_meta[k], str):\n",
    "        key_genre_om.append(literal_eval(train_genre_meta[k])[0]['genre_title'])\n",
    "    else:\n",
    "        key_genre_om.append('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_match(A, B):\n",
    "    ele_A = set(map(str.lower, A))\n",
    "    ele_B = set(map(str.lower, B))\n",
    "    return bool(ele_A & ele_B)\n",
    "\n",
    "key_genre_om_align = []\n",
    "\n",
    "for item in key_genre_om:\n",
    "    key_genre_om_item = re.split('[^a-zA-Z]', item)\n",
    "    genre_match = 'other'\n",
    "    for genre in aligned_genre:\n",
    "        genre_item = re.split('[^a-zA-Z]', genre)\n",
    "        if list_match(key_genre_om_item, genre_item):\n",
    "            genre_match = genre\n",
    "            continue\n",
    "    key_genre_om_align.append(genre_match)\n",
    "    \n",
    "key_genre_om = key_genre_om_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'pop_roc': 826,\n",
       "         'other': 11335,\n",
       "         'country_folk': 1053,\n",
       "         'jazz_blue': 778,\n",
       "         'latin_soul': 76,\n",
       "         'classical': 847})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(key_genre_om)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14915, 512) (14915,) (14915,)\n"
     ]
    }
   ],
   "source": [
    "X_train_om = feature_clip[idx_train]\n",
    "Y_om = np.ones(len(X_train_om))\n",
    "Y_genre_om = np.array(key_genre_om)\n",
    "\n",
    "print(X_train_om.shape, Y_om.shape, Y_genre_om.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19954, 512) (19954,) (19954,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.vstack((X_train_ir, X_train_om))\n",
    "Y = np.hstack((Y_ir, Y_om))\n",
    "Y_genre = np.hstack((Y_genre_ir, Y_genre_om))\n",
    "\n",
    "print(X_train.shape, Y.shape, Y_genre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'pop_roc': 2679,\n",
       "         'classical': 2087,\n",
       "         'jazz_blue': 2317,\n",
       "         'country_folk': 1418,\n",
       "         'latin_soul': 118,\n",
       "         'other': 11335})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(Y_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pop_roc', 'jazz_blue', 'classical', 'country_folk', 'latin_soul']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2679, 512) (2679,) Counter({0.0: 1853, 1.0: 826})\n",
      "(2317, 512) (2317,) Counter({0.0: 1539, 1.0: 778})\n",
      "(2087, 512) (2087,) Counter({0.0: 1240, 1.0: 847})\n",
      "(1418, 512) (1418,) Counter({1.0: 1053, 0.0: 365})\n",
      "(118, 512) (118,) Counter({1.0: 76, 0.0: 42})\n",
      "(5, 512)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# loop for each genre\n",
    "globals()['LDAcoef_'+embedding] = []\n",
    "\n",
    "for genre in aligned_genre:\n",
    "    X_train_sub = X_train[Y_genre == genre]\n",
    "    Y_sub = Y[Y_genre == genre]\n",
    "    print(X_train_sub.shape, Y_sub.shape, collections.Counter(Y_sub))\n",
    "\n",
    "    LDA = LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto')\n",
    "    LDA.fit(X_train_sub, Y_sub)\n",
    "\n",
    "    globals()['LDAcoef_'+embedding].append(LDA.coef_.copy())\n",
    "    \n",
    "globals()['LDAcoef_'+embedding] = np.squeeze(np.array(globals()['LDAcoef_'+embedding]))\n",
    "print(globals()['LDAcoef_'+embedding].shape)\n",
    "\n",
    "with open('models/datasep_' + embedding + debias_method + '.pickle', 'wb') as fdesc:\n",
    "    pickle.dump(globals()['LDAcoef_'+embedding], fdesc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = 'vggish'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## irmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13410, 128) (13410,)\n",
      "(6705,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b802b01e3adf4a54bdde085016756874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6705, 128) (6705,)\n"
     ]
    }
   ],
   "source": [
    "feature = np.array(embeddings['irmas'][embedding]['features'])\n",
    "keys_ori = np.array(embeddings['irmas'][embedding]['keys'])\n",
    "print(feature.shape, keys_ori.shape)\n",
    "\n",
    "key_clip = np.unique(keys_ori)\n",
    "print(key_clip.shape)\n",
    "\n",
    "feature_clip = []\n",
    "\n",
    "for key in tqdm(key_clip):\n",
    "    feature_clip.append(np.mean(feature[keys_ori[:]==key,:],axis=0))\n",
    "    \n",
    "feature_clip = np.array(feature_clip)\n",
    "key_clip = np.array([str(k, 'utf-8') for k in key_clip])\n",
    "print(feature_clip.shape, key_clip.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_train = set(pd.read_csv('irmas_train.csv', header=None, squeeze=True))\n",
    "key_train = set(pd.read_csv('irmas_train.csv', header=None, squeeze=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These loops go through all sample keys, and save their row numbers to either idx_train or idx_test\n",
    "idx_train, idx_test = [], []\n",
    "\n",
    "for k in range(len(key_clip)):\n",
    "    if str(key_clip[k]) in key_train:\n",
    "        idx_train.append(k)\n",
    "    elif str(key_clip[k]) in key_test:\n",
    "        idx_test.append(k)\n",
    "    else:\n",
    "        # This should never happen, but better safe than sorry.\n",
    "        raise RuntimeError('Unknown sample key={}! Abort!'.format(key_clip[k]))\n",
    "        \n",
    "# cast the idx_* arrays to numpy structures\n",
    "idx_train = np.asarray(idx_train)\n",
    "idx_test = np.asarray(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5039, 128) (5039,) (5039,)\n"
     ]
    }
   ],
   "source": [
    "X_train_ir = feature_clip[idx_train,:]\n",
    "print(X_train_ir.shape, Y_ir.shape, Y_genre_ir.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openmic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180000, 128) (180000,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9d5bc68e7547c3bd912fc71bee6669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 128) (20000,)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# openmic: openl3 embedding\n",
    "feature = np.array(embeddings['openmic'][embedding]['features'])\n",
    "keys = np.array(embeddings['openmic'][embedding]['keys'])\n",
    "print(feature.shape, keys.shape)\n",
    "\n",
    "key_clip = np.unique(keys)\n",
    "\n",
    "feature_clip = []\n",
    "\n",
    "for key in tqdm(key_clip):\n",
    "    feature_clip.append(np.mean(feature[keys[:]==key,:],axis=0))\n",
    "    \n",
    "feature_clip = np.array(feature_clip)\n",
    "print(feature_clip.shape, key_clip.shape)\n",
    "\n",
    "key_clip = np.array([str(k, 'utf-8') for k in key_clip])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train: 14915,  # Test: 5085\n"
     ]
    }
   ],
   "source": [
    "# train-test split\n",
    "train_set = set(pd.read_csv(data_root + 'openmic2018_train.csv', header=None, squeeze=True))\n",
    "test_set = set(pd.read_csv(data_root + 'openmic2018_test.csv', header=None, squeeze=True))\n",
    "print('# Train: {},  # Test: {}'.format(len(train_set), len(test_set)))\n",
    "\n",
    "idx_train, idx_test = [], []\n",
    "\n",
    "for idx, n in enumerate(key_clip):\n",
    "    if n in train_set:\n",
    "        idx_train.append(idx)\n",
    "    elif n in test_set:\n",
    "        idx_test.append(idx)\n",
    "    else:\n",
    "        raise RuntimeError('Unknown sample key={}! Abort!'.format(key_clip[n]))\n",
    "        \n",
    "idx_train = np.asarray(idx_train)\n",
    "idx_test = np.asarray(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14915, 128) (14915,) (14915,)\n"
     ]
    }
   ],
   "source": [
    "X_train_om = feature_clip[idx_train]\n",
    "print(X_train_om.shape, Y_om.shape, Y_genre_om.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19954, 128) (19954,) (19954,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.vstack((X_train_ir, X_train_om))\n",
    "print(X_train.shape, Y.shape, Y_genre.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA & correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2679, 128) (2679,) Counter({0.0: 1853, 1.0: 826})\n",
      "(2317, 128) (2317,) Counter({0.0: 1539, 1.0: 778})\n",
      "(2087, 128) (2087,) Counter({0.0: 1240, 1.0: 847})\n",
      "(1418, 128) (1418,) Counter({1.0: 1053, 0.0: 365})\n",
      "(118, 128) (118,) Counter({1.0: 76, 0.0: 42})\n",
      "(5, 128)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# loop for each genre\n",
    "globals()['LDAcoef_'+embedding] = []\n",
    "\n",
    "for genre in aligned_genre:\n",
    "    X_train_sub = X_train[Y_genre == genre]\n",
    "    Y_sub = Y[Y_genre == genre]\n",
    "    print(X_train_sub.shape, Y_sub.shape, collections.Counter(Y_sub))\n",
    "\n",
    "    LDA = LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto')\n",
    "    LDA.fit(X_train_sub, Y_sub)\n",
    "\n",
    "    globals()['LDAcoef_'+embedding].append(LDA.coef_.copy())\n",
    "    \n",
    "globals()['LDAcoef_'+embedding] = np.squeeze(np.array(globals()['LDAcoef_'+embedding]))\n",
    "print(globals()['LDAcoef_'+embedding].shape)\n",
    "\n",
    "with open('models/datasep_' + embedding + debias_method + '.pickle', 'wb') as fdesc:\n",
    "    pickle.dump(globals()['LDAcoef_'+embedding], fdesc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YAMNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = 'yamnet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## irmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33525, 1024) (33525,)\n",
      "(6705,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee7a60af0e1441ea984f97bea896c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6705, 1024) (6705,)\n"
     ]
    }
   ],
   "source": [
    "feature = np.array(embeddings['irmas'][embedding]['features'])\n",
    "keys_ori = np.array(embeddings['irmas'][embedding]['keys'])\n",
    "print(feature.shape, keys_ori.shape)\n",
    "\n",
    "key_clip = np.unique(keys_ori)\n",
    "print(key_clip.shape)\n",
    "\n",
    "feature_clip = []\n",
    "\n",
    "for key in tqdm(key_clip):\n",
    "    feature_clip.append(np.mean(feature[keys_ori[:]==key,:],axis=0))\n",
    "    \n",
    "feature_clip = np.array(feature_clip)\n",
    "key_clip = np.array([str(k, 'utf-8') for k in key_clip])\n",
    "print(feature_clip.shape, key_clip.shape)\n",
    "\n",
    "key_train = list(pd.read_csv('irmas_train.csv', header=None, squeeze=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_train = set(pd.read_csv('irmas_train.csv', header=None, squeeze=True))\n",
    "key_train = set(pd.read_csv('irmas_train.csv', header=None, squeeze=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5039, 1024) (5039,) (5039,)\n"
     ]
    }
   ],
   "source": [
    "# These loops go through all sample keys, and save their row numbers to either idx_train or idx_test\n",
    "idx_train, idx_test = [], []\n",
    "\n",
    "for k in range(len(key_clip)):\n",
    "    if str(key_clip[k]) in key_train:\n",
    "        idx_train.append(k)\n",
    "    elif str(key_clip[k]) in key_test:\n",
    "        idx_test.append(k)\n",
    "    else:\n",
    "        # This should never happen, but better safe than sorry.\n",
    "        raise RuntimeError('Unknown sample key={}! Abort!'.format(key_clip[k]))\n",
    "        \n",
    "# cast the idx_* arrays to numpy structures\n",
    "idx_train = np.asarray(idx_train)\n",
    "idx_test = np.asarray(idx_test)\n",
    "\n",
    "X_train_ir = feature_clip[idx_train,:]\n",
    "print(X_train_ir.shape, Y_ir.shape, Y_genre_ir.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openmic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380000, 1024) (380000,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48243c39c749458b95ec5ee72a2b9e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1024) (20000,)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# openmic: openl3 embedding\n",
    "feature = np.array(embeddings['openmic'][embedding]['features'])\n",
    "keys = np.array(embeddings['openmic'][embedding]['keys'])\n",
    "print(feature.shape, keys.shape)\n",
    "\n",
    "key_clip = np.unique(keys)\n",
    "\n",
    "feature_clip = []\n",
    "\n",
    "for key in tqdm(key_clip):\n",
    "    feature_clip.append(np.mean(feature[keys[:]==key,:],axis=0))\n",
    "    \n",
    "feature_clip = np.array(feature_clip)\n",
    "print(feature_clip.shape, key_clip.shape)\n",
    "\n",
    "key_clip = np.array([str(k, 'utf-8') for k in key_clip])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train: 14915,  # Test: 5085\n"
     ]
    }
   ],
   "source": [
    "# train-test split\n",
    "train_set = set(pd.read_csv(data_root + 'openmic2018_train.csv', header=None, squeeze=True))\n",
    "test_set = set(pd.read_csv(data_root + 'openmic2018_test.csv', header=None, squeeze=True))\n",
    "print('# Train: {},  # Test: {}'.format(len(train_set), len(test_set)))\n",
    "\n",
    "idx_train, idx_test = [], []\n",
    "\n",
    "for idx, n in enumerate(key_clip):\n",
    "    if n in train_set:\n",
    "        idx_train.append(idx)\n",
    "    elif n in test_set:\n",
    "        idx_test.append(idx)\n",
    "    else:\n",
    "        raise RuntimeError('Unknown sample key={}! Abort!'.format(key_clip[n]))\n",
    "        \n",
    "idx_train = np.asarray(idx_train)\n",
    "idx_test = np.asarray(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14915, 1024) (14915,) (14915,)\n",
      "(19954, 1024) (19954,) (19954,)\n"
     ]
    }
   ],
   "source": [
    "X_train_om = feature_clip[idx_train]\n",
    "print(X_train_om.shape, Y_om.shape, Y_genre_om.shape)\n",
    "\n",
    "X_train = np.vstack((X_train_ir, X_train_om))\n",
    "print(X_train.shape, Y.shape, Y_genre.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA & correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2679, 1024) (2679,) Counter({0.0: 1853, 1.0: 826})\n",
      "(2317, 1024) (2317,) Counter({0.0: 1539, 1.0: 778})\n",
      "(2087, 1024) (2087,) Counter({0.0: 1240, 1.0: 847})\n",
      "(1418, 1024) (1418,) Counter({1.0: 1053, 0.0: 365})\n",
      "(118, 1024) (118,) Counter({1.0: 76, 0.0: 42})\n",
      "(5, 1024)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# loop for each genre\n",
    "globals()['LDAcoef_'+embedding] = []\n",
    "\n",
    "for genre in aligned_genre:\n",
    "    X_train_sub = X_train[Y_genre == genre]\n",
    "    Y_sub = Y[Y_genre == genre]\n",
    "    print(X_train_sub.shape, Y_sub.shape, collections.Counter(Y_sub))\n",
    "\n",
    "    LDA = LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto')\n",
    "    LDA.fit(X_train_sub, Y_sub)\n",
    "\n",
    "    globals()['LDAcoef_'+embedding].append(LDA.coef_.copy())\n",
    "    \n",
    "globals()['LDAcoef_'+embedding] = np.squeeze(np.array(globals()['LDAcoef_'+embedding]))\n",
    "print(globals()['LDAcoef_'+embedding].shape)\n",
    "\n",
    "with open('models/datasep_' + embedding + debias_method + '.pickle', 'wb') as fdesc:\n",
    "    pickle.dump(globals()['LDAcoef_'+embedding], fdesc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "621.778px",
    "left": "21px",
    "top": "111.139px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
